<!DOCTYPE html>
<!-- saved from url=(0073)http://pieroit.github.io/machine-learning-open-course/applications.html#/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		

		<title>Machine Learning - Applications</title>

		<meta name="description" content="Machine learning applications and best practices">
		<meta name="author" content="Piero Savastano">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

        <link rel="icon" type="image/x-icon" href="http://pieroit.github.io/machine-learning-open-course/favicon.ico">

		<link rel="stylesheet" href="./decision_tree_files/reveal.css">
		<link rel="stylesheet" href="./decision_tree_files/moon.css" id="theme">
        <link rel="stylesheet" href="./decision_tree_files/pieroit.css">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="./decision_tree_files/zenburn.css">

		<!-- Printing and PDF exports -->
        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                        inlineMath: [ ['$','$'], ['\\(','\\)'] ]
                     }
            }
        );
        </script>
        <script src="./decision_tree_files/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script><link rel="stylesheet" type="text/css" href="./decision_tree_files/paper.css">
        
		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body style="transition: -webkit-transform 0.8s ease;">

		<div class="reveal slide center" role="application" data-transition-speed="default" data-background-transition="fade">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides" style="width: 960px; height: 700px; left: 50%; top: 50%; bottom: auto; right: auto; transform: translate(-50%, -50%) scale(0.847286);">

                <!-- Intro -->
				<section class="present" style="top: 163.5px; display: block;">
					<h2><a href="./tree.html">Decison Tree</a></h2>
                    <ul>
                    	<li>Overview</li>
                        <li>ID3</li>
                        <li>C4.5</li>
                        <li>CART</li>
                    </ul>
				</section>

				<!-- Business tips -->
				<section hidden="" aria-hidden="true" class="future" style="top: 330px;">
					<h4>Overview</h4>
                    
                    <style>
                        .container{
                            display: flex;
                            }
                        .col{
                            flex: 1;
                            }
                    </style>
                    <section>
	                    <p>Decision Tree models using 2 steps: <strong>Induction and Pruning</strong></p>
	                    <div class="container">

	                        <div class="col" align="left" style="font-size: 24px">
	                            <p>Induction</p>
	                            <ol>
	                            	<li>Begin with your training dataset, which should have some feature variables and classification or regression output.</li>
	                            	<li>Determine the “best feature” in the dataset to split the data on
	                            		<p>Regression: $E=\sum(Y-\hat{Y})^2$</p> 
	                            		<p>Classification: $E=\sum(p_k*(1-p_k))$</li>
	                            	<li>Split the data into subsets that contain the possible values for this best feature. This splitting basically defines a node on the tree</li>
	                            	<li>Recursively generate new tree nodes by using the subset of data created from step 3</li>
	                            </ol>
	                        </div>

	                        <div class="col" align="left" style="font-size: 24px">
	                            <p>Pruning</p>
	                            <ul>
	                            	<li>Setting the correct value for minimum number of instances per node can be challenging</li>
	                            	<li>Tree pruning is a technique that leverages this splitting redundancy to remove i.e prune the unnecessary splits in our tree</li>

	                            	<li>From strict and rigid decision boundaries into ones that are more smooth and generalise better, effectively reducing the tree complexity</li>
	                            	<li>A simple yet highly effective pruning method is to go through each node in the tree and evaluate the effect of removing it on the cost function</li>
	                            </ul>
	                        </div>
	                    </div>
	                </section>
	                <section>
	                	<h4>Example</h4>
	                	<img src="./decision_tree_files/dt_example.png" height="450" width="800">
	                </section>
	                <section>
	                	<div class="container">
	                        <div class="col" align="left" style="font-size: 24px">
	                        	<p>Pros:</p>
	                        	<ul>
	                        		<li>Easy to understand and interpret</li>
	                        		<li>Require very little data preparation</li>
	                        		<li>The cost of using the tree for inference is logarithmic in the number of data points used to train the tree</li>
	                        	</ul>
	                        </div>
	                        <div class="col" align="left" style="font-size: 24px">
	                        	<p>Cons:</p>
	                        	<ul>
	                        		<li>Overfitting is quite common</li>
	                        		<li>Not good for imbalanced dataset</li>
	                        	</ul>
	                        </div>
	                    </div>
	                </section>
	                <section>
	                	<p align="left">ID3, C4.5, and CART all adopt a top-down, recursive, divide-and-conquer approach to decision tree induction.</p>
	                	<ul>
	                		<li>
    							Information gain - used in the ID3 algorithm </li>
    						<li> Gain ratio - used in the C4.5 algorithm </li>
    						<li> Gini index - used in the CART algorithm  </li>
	                	</ul>
	                </section>
				</section>

                <!-- Summary of web applications -->
				<section hidden="" aria-hidden="true" class="future" style="top: 162px; display: block;">
					<h4>Iterative Dichotimiser 3 (ID3)</h4>
                    <div style="font-size: 24px">
					    <ul align="left">
                            <li>信息熵回顾：$$H(X)=-\sum_{k=1}^N p_klog_2(p_k)$$</li>
                            <li>the information gain of dividing the sample set $D$ by the attribute $a$ is:
                            	<p>$$G(D,a)=H(x)-\sum_{v=1}^V\frac{|D^v|}{|D|}H(D^v)$$</p> 
                            	<p>$V$ is the possible value of all the attributes $a$</p>
                            </li>
					   </ul>
                    </div>
				</section>

                <!-- Classification -->
                <section hidden="" aria-hidden="true" class="future" style="top: 330px; display: none;">
                    <h4>C4.5 </h4>
                    <ul>
                        <li>C4.5 algorithm can be seen as an improvement to the ID3 algorithm</li>
                        <li>In order to balance the information gain and the number of attributes, the information gain is introduced:
                        	<p>$G_r=\frac{G(D,a)}{IV(a)}$</p> 

                        	<p>$IV(a)=\frac{|D^v|}{|D|}log_2\frac{|D^v|}{|D|}$</li>

                        
                    </ul>
                </section>

                <!-- Regression -->
                <section hidden="" aria-hidden="true" class="future" style="top: 330px; display: none;">
                    <h4>CART</h4>
                    <section>
                        <p>Classification and Regression Tree</p>
                        <div>
                            <p align="left">Gini index: $$Gini(D)=1-\sum_{k=1}^N p_k^2$$</p>
                            <p align="left">Gini index of attribute $a$: $$Gini_a=\sum_{v=1}^V \frac{|D^v|}{|D|}Gini(D^v)$$</p>
                        </div>  
                    </section>
                </section>
                
			</div>

		<div class="backgrounds"><div class="slide-background present" data-loaded="true" style="display: block;"></div><div class="slide-background future" data-loaded="true" style="display: block;"></div><div class="slide-background future" data-loaded="true" style="display: block;"></div><div class="slide-background future" style="display: none;"></div><div class="slide-background future" style="display: none;"></div><div class="slide-background future" style="display: none;"></div><div class="slide-background future" style="display: none;"></div><div class="slide-background future" data-background-hash="img/facepalm.jpgnullnullnullnullnullnullnullnull" style="display: none;"></div><div class="slide-background future" data-background-hash="img/wikidata.pngnullnullnullnullnullnullnullnull" style="display: none;"></div><div class="slide-background stack future" style="display: none;"><div class="slide-background present" style="display: none;"></div><div class="slide-background future" style="display: none;"></div><div class="slide-background future" style="display: none;"></div></div></div><div class="progress" style="display: block;"><span style="width: 0px;"></span></div><aside class="controls" style="display: block;"><button class="navigate-left" aria-label="previous slide"></button><button class="navigate-right enabled" aria-label="next slide"></button><button class="navigate-up" aria-label="above slide"></button><button class="navigate-down" aria-label="below slide"></button></aside><div class="slide-number" style="display: none;"></div><div class="speaker-notes" data-prevent-swipe=""></div><div class="pause-overlay"></div><div id="aria-status-div" aria-live="polite" aria-atomic="true" style="position: absolute; height: 1px; width: 1px; overflow: hidden; clip: rect(1px 1px 1px 1px);">
					Machine Learning
                    Applications and practices
				</div></div>

		<script src="./decision_tree_files/head.min.js.下载"></script>
		<script src="./decision_tree_files/reveal.js.下载"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script><script type="text/javascript" src="./decision_tree_files/highlight.js.下载"></script><script type="text/javascript" src="./decision_tree_files/zoom.js.下载"></script><script type="text/javascript" src="./decision_tree_files/notes.js.下载"></script>

	

</body></html>